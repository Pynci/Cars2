behaviors:
  BlueCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  RedCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  GreenCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  RoseCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  YellowCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  VioletCar:
    trainer_type: ppo
    hyperparameters:
      batch_size: 512               # batch grandi per stabilità
      buffer_size: 2048             # aggiornamenti più frequenti
      learning_rate: 3.0e-4         # buon compromesso tra velocità e stabilità
      learning_rate_schedule: linear
      beta: 3.0e-2                  # regolarizzazione dell'entropia
      epsilon: 0.2                  # clipping di PPO
      lambd: 0.95                   # GA‑lambda per l'estimate advantage
      num_epoch: 3                  # passaggi di ottimizzazione per buffer
    network_settings:
      normalize: true
      hidden_units: 512             # rete più ampia per task complesso
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      curiosity:                    # segnale di esplorazione aggiuntivo
        gamma: 0.99
        strength: 0.1
    max_steps: 5000000             # ~5 milioni di passi, ovvero qualche ora
    time_horizon: 128              # orizzonte medio per bootstrapping
    summary_freq: 5000             # log ogni 5k passi
    keep_checkpoints: 5
    threaded: true

  